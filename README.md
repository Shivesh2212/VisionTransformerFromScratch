# Vision Transformer Implementation

## Overview

This repository contains the implementation of a Vision Transformer (ViT) where a Convolutional Neural Network (CNN) architecture is utilized as an embedding layer. Additionally, custom two-dimensional positional embeddings have been implemented.

## Implementation Details

- **Embedding Architecture:** The model incorporates a CNN architecture for the embedding layer, providing a powerful feature extraction mechanism.

- **Positional Embeddings:** Two-dimensional positional embeddings have been specifically designed and implemented to enhance the spatial awareness of the model.

## Training Considerations

Due to resource constraints, the model was not trained on a large dataset as ViTs are known to be data-hungry. As a result, the accuracy improvement was limited. While the architecture and embeddings were implemented successfully, future work could involve training on a more extensive dataset to further enhance model performance.
